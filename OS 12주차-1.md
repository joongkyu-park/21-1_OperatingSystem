# OS 12주차-1

10장. 버츄얼 메모리

2)
4가지를 배운다.

3)
Demand paging

기본적인 매커니즘을 잘 살펴보자.

이전에 Dynamic linking, loading 무엇이었나.
링킹(런타임까지)과 로딩(실제 해당 루틴이 호출될때까지)을 가능한 뒤로 미루는것

이것도 마찬가지.
Demand paging은
페이징을 요청이 있을때 까지 뒤로미룬다.

페이징이 필요할 때야 비로소 메모리 위로 올린다.
-> 한마디로 Lazy swapper 라고 한다.

예를들어 프로세스가 5개의 페이지로 구성되어있다.
![OS 12주차-1](images/OS%2012주차-1.png)

하나의 페이지만 접근하고, 나머지 4개의 페이지는 안쓰기 때문에 로딩 x

나머지 페이지는 요청(demand)가 있을 때, 그 때 비로소 메모리 어느 공간에 로딩한다.

만약 3개의 페이지는 요청이 전혀 없었다. 로딩 될까 안될까?
-> 안된다.
![OS 12주차-1-1](images/OS%2012주차-1-1.png)

이전까지 swapping은 단위가 프로세스 였다.
메모리에서 전체 프로세스를 쫓아내고, 불러오고…

-> 그러나 이제 demand paging이 사용되면서,
paing, pager가 더 적절한 표현이 되었다.
왜냐하면 쫓겨나고 메모리에 로딩되고 이 단위가 프로세스가 아니라 페이지이기 때문.

4)
다음과 같다.

5)
이제 생각을 바꾸자,

프로세스 전체가 아니라 프로세스 중 일부만 메모리에 있을 것이다.

메모리에 있는 페이지와 메모리에 없는 페이지를 어떻게 분류할까.
-> valid & invalid bits 활용

v -> in-memory
i -> not-in-memory, illegal(둘 다)

이전엔
v -> legal
i -> illegal
이었는데 모델이 바뀌었다.

처음에 프로세스를 생성하는 시점에는
모든 페이지가 i(illegal)일 것이다.
왜냐면 처음엔 아직 요청이 없으므로 메모리에 로딩되지 않았으니까
![OS 12주차-1-2](images/OS%2012주차-1-2.png)

6)
예시.

현제 메모리에 있는것
A C F

A->0번 페이지
C->2
F->5

0,2,5 -> v
나머지 -> i (메모리로 아직 로딩이 안된거고, demand가 아직까지 없는거다)

페이테이블에 있는 넘버가 frame 넘버가 되겠다.

“page fault” 발생
요청한 페이지가 메모리에 없는 경우.
요청한 페이지를 메모리 위로 올려야한다.
그 스텝에 대해 살펴보자

7)
page-fault trap
요청한 페이지가 피지컬 메모리에 없을 때. i/v로 판단.
한마디로 trap -> s/w interrupt로써 처리한다는 듯. -> Exeception으로 여겨서 처리한다는뜻

page-fault 가 발생했을 때 수행해야하는 os의 액션
총 6개의 스텝
1. i이니까 단순하게 메모리에 없는건지, invaild인건지 판단. 두 가지중 어느거냐.  Invalid 확인을 위해서 process control block의 또다른 테이블을 lookup해서 확인해야함. -> invaild가 맞다면, abort 임. -> stop  메모리에 없다면, 다음 스텝 진햄
2. 메모리(프레임) 공간 확보해야한다.
3. 페이지를 메모리(프레임)으로 올린다. 요청한 페이지를 메모리로 올리는 상황. 이 때 waiting state로 전환. 왜? 스와핑 하는 과정이 입출력을 하는 것이니까.
4. 테이블을 업데이트
5. 해당 validation bit를 v로
6. intstruction 재수행

8)
그림으로 보자.

9)
page fault 처리하는데에 시간이 오래걸리겠다.
근본적인 이유?
backing store에 접근하기 때문에.

처음에는 메모리에 프로세스가 없기때문에, 무조건 page fault가 발생할 것인데. 추후에도 page fault가 많이 발생할 것이다..

그러나 page fault가 많이 발생하지 않는다.
실제 프로그램에 접근은 “locality of reference”를 따르기 때문에,
demand paging을 쓰더라도 합리적인 성능을 낸다.

locality of reference?
특정 페이지를 집중적으로 접근함.
특정 지역만 집중적으로 접근하는 성향.
모든 페이지를 다 로딩할 필요가 없다.

10)
page fault rate에 따른 demand paging의 퍼포먼스.

11)
실제 시간을 가지고 분석해보자.

page fault service time이 많이 걸리는 이유?
backing store를 접근해야하기 때문에.
메모리 접근시간과 비교하여 어마어마하게 크다.. 이 시간을 줄이는게 중요하겠다.

if page fault rate가 1/1000이라면?
EAT = 8.2
page fault  rate가 0이라면 EAT = 0.2
=> 대략 40배
=> page fault 를 줄이는 것을 절실히 느낀다… 최소화 하는 것이 중요하다…

12)
분석을 더해보았다.

기존은 0.2 microseconds였다(page fault 가 아예 없을 때)
10프로 degradatiojn을 위해 최대 0.22 micro-sec 까지 걸리게 하려면,
P<0.0000025가 되어야한다…

시간을 더 줄이는 방법?
-page fault count를 줄인다. 당연..
-fault가 발생했을 때 swapping overhead를 줄인다.
![OS 12주차-1-3](images/OS%2012주차-1-3.png)

disk에 swap을 위한 backing store 존재. 이 공간을 관리해주므로써 시간을 더 줄일 수도 있다.

13)
두번째 토픽.
Page Replacement. 페이지 교체.

어떤 페이지를 쫓아내야하는데, 누구를 쫓아낼 것이냐.

목표는 page fault의 횟수를 줄이는 것.
->미래에 접근될 개연성이 높은 페이지는 쫓아내면 안되겠다.

페이지가 메모리 없어
1. 요청할 페이지를 저장할 위치를 찾는다.
2. 비어있는 프레임을 찾는다 비어있는 프레임있다 -> 바로사용하면됨 없다 -> 페이지 교체 알고리즘이 적용되어야한다. (replacement algorithm)
3. 비어있는 프레임이 확보되면, 페이지를 로딩하면 된다.
4. 프로세스 재실행

다시 정리.
physical memory가 다 꽉차있다.
-> backing store에서 요청한 페이지를 로드해야함.
-> 피지컬 메모리에 1~10000번(예)페이지가 있는데, 어떤거와 replacement 할 것이냐

14)
예를 들어 쫓아낼 페이지를 결정함(victim page)

victim을 swap out하고, 새로운 페이지를 swap in하고
각각 valid-invalid bit를 i, v로 바꿔 주어야한다.

이 때 디스크 access를 2번해야한다.
스와핑 아웃할 때 write, 스와핑 인할 때 read
-> 이 오버헤드가 크다.

그러나, 스와핑아웃 하는것이 반드시 필요할까?
필요하지 않을 경우가 있을 수 있다.
해당 페이지(victim)가 수정(modify)가 안되었으면, 디스크에 있는 내용과 똑같으므로 write할 필요가 없다.
따라서 해당페이지가 메모리로 로딩되고나서 modify가 되었을 경우에 한해서만 swap out이 필요하다.
-> swap out을 안하면 오버헤드를 반으로 줄일수 있다.

15)
modify bit를 가지고,
modify bit가 1일 경우에만 swap out 시킨다.

16)
교체 알고리즘.

목표 : page-fault rate을 최소화

reference string는 접근하는 순서

17)
demand paging을 쓸경우 맨 처음 요청하는 페이지는 메모리에 무조건 없으므로, page fault가 당연히 발생하겠다.

프레임 3개일때
1번 요청 -> page fault 발생
2번 요청 -> page fault 발생
3번 요청 -> page fault 발생
4번이 요청되었을 때, 누군가를 쫓아내어야한다.

FIFO 알고리즘 : 처음에 도착한 놈을 쫓아낸다
-> 1번이 victim이 되겠다.

(메모리 : 4 2 3)

1번 요청 -> 2번 쫓아냄 (메모리 : 4 1 3)
2번 요청 -> 3번 쫓아넴 (메모리 : 4 1 2)
…

-> 이러한 reference string일 때 page fault이 9번 발생했다..

프레임이 4개일 때
…
-> page fault 10번.

page fault의 횟수를 최소화하는게 목적이므로, 프레임이 3개인 상황이 더 좋겠다.
뭔가 상식적이지않다.
프레임 갯수가 늘었는데, page fault가 늘어나는..
=> Belady의 기현상
FIFO에서는 이런 기현상이 발생할 수 있다.

18)
FIFO
먼저온 놈을 쫓아낸다.

좋은 알고리즘이 아니어 보인다.

19)
최적은?
미래에 가장 오래기간 동안 사용안되는 페이지를 교체하는게 최적.

교재의 예시에서,
5번이 요청될 때, 가장 오래동안 요청이 안되는 페이지는 4번이므로, 4번을 교체하게 되겠다.

최적이다. 그러나 문제가 있다. -> 미래에 어떤 페이지를 접근할 지 알 수없다.
-> 비현실적인 알고리즘
-> 따라서 다른 알고리즘의 성능을 측정할 때만 사용

20)
예시

21)
미래는 모르기때문에, 과거를 보고 선택해야한다.
-> LRU 알고리즘.
LRU을 선택한다. Least Recently Used

교재의 예시에서, 5번을 요청했을 때
LRU을 쫓아내야한다 -> 3

22)
LRU 예시
…
![OS 12주차-1-4](images/OS%2012주차-1-4.png)

23)
구현상에 이슈가 있을 수있다.
2가지 구현방법
- Counter implementation 논리적 Counter 시간에 의하여 판단. 시간이 지날수록 +. Counter 값이 가장 작은 것을 victim으로 선택
- Stack implementation (자료구조때의 LIFO를 생각하면안된다..! 스택의 메커니즘은 싸그리 무시하자..) 순서를 유지하는것. 항상 맨 밑에 있는 LRU를 쫓아낸다.

![OS 12주차-1-5](images/OS%2012주차-1-5.png)

24)
Counter implementation

Counter값이 가장 작은 것을 쫓아낸다.
searching이 필요하다. 누가 가장 작은지 비교해야하기 때문에.

25)
Stack implementation

searching이 필요하지 않다.
(stack을 관리하는 오버헤드는 있다.)

