# os 2주차-1

지난시간에 이어서 chapter 1

16)
Interrupt

DMA 개념 다시생각해보자.
cpu간섭없이 io트랜잭션을 수행할수있다.
-> io요청 수행을 하고 나서 cpu는 다른 프로세스를 수행할 수 있다.
-> concurrency(멀티태스킹)이 핵심
여기서 이슈.
io가 끝났을 때 cpu에게 알려줘야하는데, 그게 interrupt.

interrupt가 발생하면, 모든 interrupt 소스는 그 Interrupt가
발생했을 때 수행되어야할 루틴(함수)가 존재.
이것을 ISR 또는 Interrupt handler 라고 부름.
함수로 되어있다.
무조건 ISR을 가진다.

위치는 어떻게 찾냐? -> by. interrupt vector
interrupt vector는 테이블인데,
소스와 isr주소를 가지고있다.
cpu는 interrupt가 발생하면 이 테이블부터 확인해서
interrupt handler로 쩜프하게된다.

가장많이 발생되는 interrupt -> timer interrupt handle
(리눅는 10ms에 1번씩)
->
os는 interrupt driven하다. interrupt가 너무 자주일어나서,
-> interrupt에 의해 수행된다고 해도 과언이 아니다.

17)

18)
맨 처음에 interrupt가 유발된 곳의 어드레스를 저장하는 이유는,
interrupt handler가 끝나고 다시 원래수행했던 위치로 돌아와야하기 때문

19)

20)
interrupt라고 일반적으로 부르는 것은 하드웨어에 의한것.
외부 디바이스에 의해서. 외부에서 발생하는 interrupt.
외부에서 비동기적으로 발생. 당연히 알수가 없음.

그렇다면,
소프트웨어도 interrupt를 발생시킨다 -> O
->그걸 특별히 Trap 이라고 한다.
동기적임. 내부프로그램의 수행결과로써 발생

Trap은 2가지가 있다.
1. System call : OS에게 서비스를 요청할 수 있는 유일한 메카니즘 시스템콜은 api, 즉 함수형태로써 표현이 된다.
2. Segmentation fault(=Exception)

-> Trap은 원인이 내부에 있다.

21)
지금까진 io관련.

Storage structure
1. Main memory(primary memory) -> DRAM 프로그램을 수행시키기위해서 메인메모리로 로드시켜놓는데,  cpu가 인터랙션할 수 있는 유일한 매체 -> volatile의 특성. 전원을 끄면 사라짐
2. Secondary storage -> HDD(Hard Disk Drive), SSD(Solild State Disk) 데이터를 저장하기 위한 목적. -> nonvolatile이어야 함.
3. Tertiary Storage backup용 옛날에는 Tape으로도 했었음. 요즘은 Cloud

22)
Storage를 배울 때 핵심
-> 가격 측면때문에 Trade-off 가 있다.
-> 그래서 caching, prefecthing이라는 기법이 필요. caching : 자주 접근되는 데이터는 빠른 storage medium에 올려둔다.
prefetcing 한번갈때미리 읽어들인다.

맨위 3개는 데이터저장용으로 쓰일 수없다. volatile

caching기법이 중요한 설계 원칙으로 필요하다.

23)
가격, 성능이 다르기때문에
Caching 기법이 매우 중요하다!

24)
데이터를 읽고 쓸 때 cache를 먼저 체크.
-> cache에 없으면 느린 storage medium 확인하러감

Cache는 공간이 작기 때문에, 효과적으로 쓰는 것이 중요하다.

25)
아키텍쳐 토픽으로 넘어가보자.

최근에는 멀티프로세서, 멀티코어시스템이 많이 쓰인다.

멀티코어 : cpu는 하나. core(실행유닛)가 여러개 있음.
멀티프로세스 : cpu 자체가 여러개 있음.

성능을 크게 증가시킬수없어써 멀티코어가 필수불가결.
cpu성능척도인 기가헤르츠를 크게 증가시키지 않는 이유 -> 전력문제

26)
해당 그림은 멀티프로세서다. cpu자체가 여러개.

cpu가 n개 있다고 n배의 성능이 나는건 아니다.
이유.
cpu끼리 커뮤니케이션하는데에서 이슈 존재.
overhead 이슈 존재.

27)
멀티프로세서 시스템의 타입.
1. 비대칭척인 멀티프로세싱 비대칭적이다? cpu간의 상하관계(master-slaves 관계)가 있을 때 master 프로세서, slaves 프로세서. 특징) 자기만의 메모리공간을 가질수 있음. privite 메모리가 있음
2. 대칭적인 멀티프로세싱 cpu간의 상하관계 없음 특징) shared 메모리를 씀.

28)
그림

29)
메모리를 접근하는 모델은 크게 2가지
1. 어떤 cpu에서건 메모리 접근하는데에 동일한 시간이 걸린다
2. 메모리하고 cpu 거리관계에 따라 메모리 access시간이 틀릴 수 있다.

30)
멀티코어시스템
cpu내에(동일한 칩내에) 여러개의 코어가 있다.
전력문제때문에 필수불가결하게 최근에는 멀티코어를 쓴다.
물론 서버같은 대규모 시스템은 당연히 멀티프로세스도 쓰고 멀티코어도 쓴다. 혼합으로.
os가 중요한 이유
프로세스가 여러개있는데
프로세스를 어느코어에 있는지 할당하는것이 os.

31)
오퍼레이팅시스템 구조

멀티프로그래밍(또는 멀티태스킹)
여러 프로세스가 concurrently 수행된다.
이유. cpu가 io명령을 내리고나서 다른일을 수행할수 있기 때문
cpu와 io디바이스를 최대한 바쁘게 일을 시키는게 목표

표현) job = process = task (현재 수행중인 프로그램)

scheduling이 핵심적이다.

여러개의 job을 빠르게 번갈아가면서 실행.
job들간의 switch가 중요. context switch

32)

33)
멀티프로그래밍. OS가 중요한 근본적인 이유.
아래의 개념들이 출현한이유는 멀티프로그래밍 때문!!
1. CPU scheduling
2. Job scheduling : 어떤 잡을 메모리로 올릴것이냐
3. swapping : 메모리가 공간은 한정되어있는데 프로그램은 여러개기때문에 프로그램들은 swap in, swap out 해야한다.
4. virtual memory. 한마디로 os에서 더 큰 메모리공간을 사용하는것. 공간크기는 아키텍쳐의 bit의 의존적이다. 32bit 주소체계면 약 4GB. -> 가상이기때문에 가능한것.
5. Process : 현재 수행중인 프로그램

34)
job scheduling
모든 job을 메모리에 올릴수없기때문에 일부 job만 올리는것.
메모리 안으로 들어온다 : swapping in
밖으로 나간다 : swapping out

35)
어떤 job을 먼저 실행할가? -> cpu scheduling

스케줄링이 잘못되면 job에 starvation이 발생할 수도있다.

36)
Modern OS is interrupt-driven이다.
가장 많이 일어나는 interrupt는 timer-interrupt.. 리눅스는 10ms당 한번..
소프트웨어 interrupt도 있다. Trap
system calll, exception.

37)
듀얼모드 operation을 지원한다.
user mode와 kernel mode로 구분
usual 프로그램 수행중?> 유저모드
operating system code 수행중? -> 커널모드
이렇게 엄격히 구분한 이유 -> 시스템 보호(protection) 때문
커널모드에서만 수행될 수있는 instructuin이 있기 때문
-> Privileged instruction
이 instruction이 user mode에서 일어나려고하면 막아야한다.

mode bit로 커널모드, 유저모드 구분한다.

