# os 12주차-2

지난 시간에 이어 10장 진행.

26)
LRU-approximation 알고리즘
 
LRU기법은 victim이 LRU 페이지로 선정.

LRU-approximation 알고리즘은 LRU와 유사한 기법.
좀 더 빠르게 LRU를 찾는 기법.
-> Reference bit를 도입 : 해당 페이지가 참조되었는지 나타내는 비트(0 또는 1).  참조되면 1

그러나 모든 페이지의 비트가 1이면, 다 똑같으므로 현실적으로 적용하기 어렵다

27)
referece bit를 여러개 두자.
-> additional-referece bit

8개의비트중 최상위비트는 가장 최근, 최하위비트는 가장 오래전을 의미.
![os 12주차-2](images/os%2012주차-2.png)

시간이 지나면 비트가 전체적으로 오른쪽으로 shift

누가 victim이 될까?
![os 12주차-2-1](images/os%2012주차-2-1.png)

2번이다.
이유는 가장 최근에 1번이 참조되었기 때문에

=> 레퍼런스 비트가 여러개있으면 매우 효과적으로 LRU를 찾을 수 있겠다.

문제점? 레퍼런스를 나타내는 비트가 여러개가 있다는것.
극복하는 방법
하나의 비트로 LRU와 유사한 성능을 내보자

28)
Second change 알고리즘 = clock 알고리즘

레퍼런스 비트가 1개.

30)
먼저 애니메이션으로 보자.

총 6개의 프레임이 있다. 각 프레임의 페이지넘버는 33, 22, 11 … 4이다.
이 때 페이지 7이 요청이왔다.
누군가 쫓겨나야하는 순간

여기서 clock알고리즘은 victim을 선택한다.
clock hand라는 포인터가 clockwise 방향으로 계속 돌고있다.
제일 처음나오는 레퍼런스비트가 0인걸 victim으로 선택. 그리고 1로바꾸어줌.
돌면서 1인것은 0으로 바꾸어줌.
![os 12주차-2-2](images/os%2012주차-2-2.png)

이 다음 victim은? -> page 12
제일 처음나오는 레퍼런스 비트가 0인 것.

29)
교재 예제.

28)
다시 설명

레퍼런스가 1이면 0으로 교체. 한번 더 기회를 준다. -> second chance.

31)
세번 째 LRU approximation 알고리즘

Enhanced Second chance 알고리즘.

레퍼런스 비트와 modify 비트를 pair로 갖는다. 하나의 튜플로.
총 4개의 clase로 구분가능
1클래스 (0,0)
2클래스 (0,1)
3클래스 (1,0)
4클래스 (1,1)

첫번째 클래스가 있다 -> victim
첫번째 클래스가 없다 -> 두번째클래스가 victim
두번째클래스가 없다 -> 세번째 클래스가 victim
..
-> 클래스가 낮을수록 비어있지 않다면, victim 우선순위가 높다.

32)
지금까지 LRU, LRU-approximation들은 언제 접근했는지를 보았다.

지금은 완전 새로운 접근
Counter-Based 알고리즘
-> 얼마나 많이 해당 페이지를 레퍼런스 했는지 중요시한다.
![os 12주차-2-3](images/os%2012주차-2-3.png)

LFU -> 가장 적은 참조한 페이지를 쫓아낸다
MFU -> 가장 많이 참조한 페이지를 쫓아낸다

일반적으로는 os에서 LRU 기법이 좋은 성능을 나타내는것으로 알려져있다.
이 frequency기반(counter 기반)알고리즘들은 os에서 별로 효과가 없고 주로 vod같은 영상시스템, 인기도 기반에 적용하는 그런 곳에 쓰인다.

33)
세번째 토픽
Thrashing

Thrashing이 뭐냐, 언제 발생하느냐.
 한마디로 메모리가 부족해서 발생하는것.
피지컬 메모리의 공간이 부족하다 -> replacement가 많이 일어난다. 
-> swapping이 많이 일어난다. -> I/O가 많이일어난다.(disk I/O) 
-> 오히려 CPU utilization이 떨어지는 현상이 발생.
이게 Thrashing.
원인은 메모리 공간이 작은것.

os는 utilization이 떨어지는게 프로세스 개수가 부족한줄알고 프로세스를 늘린다.
(degree of multiprogramming = 프로세스의 개수)
원인은 그게아닌데..

해결방법?
메모리를 큰걸 사용해야지.. 프로세스를 줄이던가, 메모리를 많이 잡아먹는 프로세스를 줄이던가.

Thrashing을 어떻게 detection 하느냐.
-> working set model을 활용해야함.

34)
원인은 메모리가 부족해서 swapping-in, swapping-out을 자주하기 때문!

요구되는 n개의 프로세스가 있을 때, 그 필요한 공간과
total 메모리 사이즈와 비교한다
![os 12주차-2-4](images/os%2012주차-2-4.png)

문제는 이 demand를 어떻게 파악할 것이냐.

35)
프로세스는 locality model 따른다.
locality는 특정 페이지만 집중적으로 접근하는 access 패턴을 의미.

그 프로세스가 요청하는 총 페이지의 수(demand)는 모든 locality를 포함시킬필요는 없다. -> 특정 시점에 집중적으로 접근하는 페이지수로 산출해도 괜찮다!

따라서 demand는 locality 값으로 변환이 된다.
![os 12주차-2-5](images/os%2012주차-2-5.png)

![os 12주차-2-6](images/os%2012주차-2-6.png)

여기서 윈도우 크기가 중요하다.
locality를 모니터링하는 윈도우의 크기가 작을수록 요구하는 페이지수가 작아지겠다.

![os 12주차-2-7](images/os%2012주차-2-7.png)

여기서 질문.
demand의 요구되는 양의 크기가
언제 over-estimation될까(과도하게 요구되는 페이지가 많을거라고 예상)  -> 윈도우의 크기가 클 때.
under-estimation -> 윈도우가 작을때

=> 따라서 윈도우 사이즈를 적절히 설정하는것이 중요
-> Working Set model

36)
윈도우사이즈 ->  레퍼런스하는 사이즈

프로세스가 접근하는 페이지의 집합.

![os 12주차-2-8](images/os%2012주차-2-8.png)

WSS = 해당 윈도우내에 접근하는 페이지의 개수
윈도우 사이즈가 크면 워킹셋의 사이즈가 증가될 개연성이 크겠다.

![os 12주차-2-9](images/os%2012주차-2-9.png)

일 때 Thrasing이 발생

37)

38)
메모리공간이 14라고 가정해보자.
윈도우사이즈는 10

프로세스 P1의 WSS1 = 6 (1,2,4,5,6,7)
WSS2 = 5
WSS3 = 4

이걸 다 더해주면 15.
15 > 14 이므로 thrashing 발생.
![os 12주차-2-10](images/os%2012주차-2-10.png)

윈도우 사이즈를 5로 줄여보자.
현시점으로 가장 가까운 과거 5개를 본다.
![os 12주차-2-11](images/os%2012주차-2-11.png)

-> thrashing 발생 X

39)
10장 메모리 파트의 마지막 토픽.

Allocating Kernel Memory

유저레벨에서 malloc 함수를 쓰면 page단위로 할당해준다. 왜냐하면 os에서 메모리 관리할 때 최소 단위가 page이기 때문.
커널프로그램은 계속 동작하고 있는 프로그램.

![os 12주차-2-12](images/os%2012주차-2-12.png)

최소단위가 4KB이라고했을때, 1KB가 낭비되는 현상 -> internal fragmentation
단위 때문에 발생함.

커널 프로세스가 계속 진행이되는데, 예를 들어 PCB.. 계속 1KB가 낭비되면 안된다.
또 메모리접근이 빨라야한다.

유저메모리 할당과 다르게 관리가 되어야한다.
-> Buddy System, Slab Allocator

40)
Buddy System

버디시스템에서 할당하는 기법의 핵심은,
옆에 비어있는 cotiguous한 페이지를 합쳐서 가능한 큰 메모리 형태로 관리하고자 함.
핵심은 power-of-2 allocatior(2의 n승 allocator)
페이지를 여러개 할당해줘야하는데, 2의 n승개 단위로 할당해준다.

예를들어 3개의 페이지를 요청했다.
-> 3개보다 같거나 큰 2의 n승개로할당해야하므로 4개 할당.

또 다른 핵심. 버디
가능한한 연속적인 메모리 공간을 크게 관리한다
즉 coalescing(병합), spliting(분할) 연산이 버디시스템에서 발생한다.

![os 12주차-2-13](images/os%2012주차-2-13.png)

그림을 통해보자

42)
가능한한 큰 연속적인 비어있는 공간을 별도로 관리하는 것이 특징. 버디를 붙여서.
연속적인 페이지가 512개가 있다.
253개 페이지가 요청이왔다.
-> 256개 할당.

연속적으로 할당하기 위해 분할.
512개의 연속적인 페이지를 256으로 스플리팅.
![os 12주차-2-14](images/os%2012주차-2-14.png)

124개 요청
-> 128개 할당, 비어있던 256 페이지를 또 splitting
![os 12주차-2-15](images/os%2012주차-2-15.png)

43)
어떻게 돌다 보니 이런 Hole들이 생겼다.

c라는 오브젝트 종료
![os 12주차-2-16](images/os%2012주차-2-16.png)

-> 3개의 빈 공간을 합쳐서 512개의 페이지로 관리 -> 병합하여서.
![os 12주차-2-17](images/os%2012주차-2-17.png)

44)
시나리오 하나더.

이와 같은 식으로 할당되어있다.
![os 12주차-2-18](images/os%2012주차-2-18.png)

128개를 할당해야한다.
-> A’에 대해서 spliting 연산이 일어나야한다.
![os 12주차-2-19](images/os%2012주차-2-19.png)

C가 128을 놨어(release)
![os 12주차-2-20](images/os%2012주차-2-20.png)

아무 연산도 안일어남. 병합가능 하지 않기때문

D가 64를 release했어.
![os 12주차-2-21](images/os%2012주차-2-21.png)

![os 12주차-2-22](images/os%2012주차-2-22.png)

C, D, D’이 병합된다.

45)
Slab allocation
내부단편화를 없애기 위함. intenal fragmentation

46)
커널에서 세마포어를 많이쓴다.
세마포어는 7KB씩 쓴다고 하자.
-> 2개의 페이지를 할당해줘야한다. 8KB
-> 매번 세마포어를 쓸 때마다 1KB가 낭비되기 때문에 낭비가 심해진다.

Slab allocation을 사용해보자.
세마포어는 커널에서 자주 사용되는게 보인다.
미래에도 사용될것이다.
-> 미리 세마포어를 위해 할당해놔주자.

예를들어 7개의 페이지를 미리 할당해놓고,
세마포어 요청이 오면 주소를 반환해준다.
![os 12주차-2-23](images/os%2012주차-2-23.png)

![os 12주차-2-24](images/os%2012주차-2-24.png)

첫번째 요청, 두번째요청, 세번째 요청…
이렇게 요청올때마다 이전의 끝나는 주소값을 줌으로써 낭비되는 공간을 없앤다.

미리 생성하고 정확하게 주소공간을 할당해주면, 내부단편화로 낭비되는 공간이 없어진다.
이와같은 연속적인 페이지들의 집합을 Slab이라고 한다.

동일 오브젝트를 모아놓은 공간 = 캐쉬 (여기서는 세마포어)
이런 캐쉬들을 위해 미리 Slab을 만들어 놓는다.

또 주소로 바로 접근하기 때문에 빠르게 메모리에 접근할 수 있다.

47)
![os 12주차-2-25](images/os%2012주차-2-25.png)

이런 상황에서 세마포어 요청이 또왔다
-> 주로 Partial slab에 used 시켜준다.

45)
Slab : 하나 또는 연속적인 페이지들의 집합.
Cache : 특정 오브젝트르 위한 하나이상의 slab으로 구성.

단편화가 없고, 빠르게 메모리에 접근할 수 있다.

